This project implements a **machine learning pipeline to detect phishing (malicious) URLs** using lexical feature engineering and supervised classification models.

The workflow includes:

* âœ… Dataset validation
* âœ… URL canonicalization
* âœ… Feature engineering
* âœ… Exploratory Data Analysis (EDA)
* âœ… Model training & evaluation
* âœ… Artifact saving for reproducibility

Dataset used:

```
malicious_phish.csv
```

---

## ğŸ“‚ Project Structure

```
project-root/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ malicious_phish.csv
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ eda/
â”‚   â””â”€â”€ metrics/
â”‚
â”œâ”€â”€ artifacts/
â”‚
â”œâ”€â”€ paths.py
â””â”€â”€ ProjectFile.ipynb
```

---

## âš™ï¸ Tech Stack

* **Python 3.8+**
* **Pandas & NumPy** â€“ Data processing
* **Scikit-learn** â€“ Machine Learning models
* **Matplotlib & Seaborn** â€“ Visualization
* **Joblib** â€“ Model serialization
* **Jupyter Notebook** â€“ Experiment workflow

---

## ğŸ” Pipeline Workflow

### 1ï¸âƒ£ Environment Setup

* Loads directory paths from `paths.py`
* Validates dataset existence
* Prepares project structure

### 2ï¸âƒ£ Feature Engineering

* URL normalization
* Lexical feature extraction
* Token-based analysis
* Structured feature matrix creation

### 3ï¸âƒ£ Exploratory Data Analysis

* Class distribution
* Feature distributions
* Summary statistics
* Saved visualizations

### 4ï¸âƒ£ Model Training

* Train/Test split
* Logistic Regression classifier
* Model performance evaluation

### 5ï¸âƒ£ Evaluation Metrics

* Accuracy
* Precision
* Recall
* F1-Score
* ROC-AUC
* Confusion Matrix

All metrics and models are saved for reproducibility.

---

## â–¶ï¸ Installation

Clone the repository:

```bash
git clone https://github.com/your-username/phishing-url-detection.git
cd phishing-url-detection
```

Install dependencies:

```bash
pip install -r requirements.txt
```

Or manually:

```bash
pip install pandas numpy scikit-learn matplotlib seaborn joblib
```

---

## ğŸš€ How to Run

1. Place `malicious_phish.csv` inside the `data/` folder.
2. Ensure `paths.py` correctly defines:

   * `PROJECT_ROOT`
   * `DATA_DIR`
   * `OUTPUTS_DIR`
   * `ARTIFACTS_DIR`
3. Launch Jupyter:

```bash
jupyter notebook ProjectFile.ipynb
```

4. Run all cells sequentially.

---

## ğŸ“Š Outputs

After execution, the project generates:

* ğŸ“ˆ EDA visualizations (`outputs/eda/`)
* ğŸ“Š Performance metrics (`outputs/metrics/`)
* ğŸ’¾ Trained model artifacts (`artifacts/`)
* ğŸ“„ Evaluation summaries

---

## ğŸ§  Key Highlights

* Modular ML pipeline design
* Clean artifact management
* Reproducible experiments
* Structured evaluation framework
* Production-ready saving of trained models

---

## ğŸ”® Future Improvements

* Cross-validation
* Hyperparameter tuning (GridSearchCV)
* Random Forest / XGBoost comparison
* API deployment (FastAPI/Flask)
* SHAP-based explainability
* Model performance dashboard

---

